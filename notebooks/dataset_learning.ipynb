{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from os.path import join\n",
    "from mssa_learning.preprocessing import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import progressbar\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from mssa_learning.models.dnn_classifier import DNNClassifier\n",
    "from model_generator.posture_classification.rnn_classifier import RNNClassifier\n",
    "import math\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_base(features, targets, nb_targets=None):\n",
    "    if nb_targets is None:\n",
    "        nb_targets = len(targets)\n",
    "\n",
    "    idx = np.arange(len(features))\n",
    "    np.random.shuffle(idx)\n",
    "    nb_samples = int(9*len(idx)/(10*nb_targets))\n",
    "    samples_per_class = np.zeros(nb_targets)\n",
    "    max_samples = np.ones(nb_targets) * nb_samples\n",
    "\n",
    "    i = 0\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    while not np.equal(samples_per_class, max_samples).all() and i<len(targets):\n",
    "        if samples_per_class[targets[i]] < nb_samples:\n",
    "            train_x.append(features[i])\n",
    "            train_y.append(targets[i])\n",
    "            samples_per_class[targets[i]] += 1\n",
    "        else:\n",
    "            test_x.append(features[i])\n",
    "            test_y.append(targets[i])\n",
    "        i += 1\n",
    "\n",
    "    for j in range(i, len(targets)):\n",
    "        test_x.append(features[j])\n",
    "        test_y.append(targets[j])\n",
    "    return np.array(train_x), np.array(train_y), np.array(test_x), np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5_pc = h5py.File(join(\"..\", \"data\", \"dataset_converted\" , \"h5\", \"pc.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcs = []\n",
    "labels = []\n",
    "nb_components = 10\n",
    "nb_labels = 5\n",
    "\n",
    "for key in h5_pc:\n",
    "    for rec in h5_pc[key]:\n",
    "        if not math.isnan(h5_pc[key][rec][0][0]):\n",
    "            label = int(key[-3:]) - 1\n",
    "            if label < nb_labels:\n",
    "                labels.append(label)\n",
    "                pcs.append(h5_pc[key][rec][:, :nb_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcs, size = dynamic_time_warping(pcs, principal_components_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_pcs = []\n",
    "flat_labels = []\n",
    "for i, pc in enumerate(pcs):\n",
    "    if len(pc) == size: \n",
    "        flat_pcs.append([x for row in pc for x in row])\n",
    "        flat_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = create_training_base(flat_pcs, flat_labels, nb_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0, dual=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_in = len(flat_pcs[0])\n",
    "H = 64\n",
    "D_out = nb_labels  # number of classes to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 100\n",
    "steps = 12000\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DNNClassifier(D_in, D_out, H, batch=batch, steps=steps, epochs=epochs, scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_errors = 0\n",
    "for i, x in enumerate(test_x):\n",
    "    y = torch.from_numpy(x).float()\n",
    "    outputs = model.forward(Variable(y))\n",
    "    # value, index = torch.max(outputs.data, 0, keepdim=True)\n",
    "    y_pred = int(outputs.data.max(0)[1])\n",
    "    if y_pred != test_y[i]:\n",
    "        nb_errors += 1\n",
    "success_rate = (len(test_x) - nb_errors) / float(len(test_x))\n",
    "print success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcs = []\n",
    "labels = []\n",
    "nb_components = 10\n",
    "nb_labels = 5\n",
    "\n",
    "for key in h5_pc:\n",
    "    for rec in h5_pc[key]:\n",
    "        if not math.isnan(h5_pc[key][rec][0][0]):\n",
    "            label = int(key[-3:]) - 1\n",
    "            if label < nb_labels:\n",
    "                labels.append(label)\n",
    "                pcs.append(h5_pc[key][rec][:, :nb_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = create_training_base(pcs, labels, nb_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_in = 10\n",
    "H = 16\n",
    "D_out = max(labels)  # number of classes to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = 50000\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RNNClassifier(D_in, D_out, H, steps=steps, epochs=epochs, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_errors = 0\n",
    "iter_example = 1000\n",
    "for i in range(iter_example):\n",
    "    x, y = model.random_example(test_x, test_y)\n",
    "    hidden = model.initHidden()\n",
    "    for i in range(x.size()[0]):\n",
    "        output, hidden = model.forward(x[i], hidden)\n",
    "    # value, index = torch.max(outputs.data, 0, keepdim=True)\n",
    "    top_n, top_i = output.data.topk(1)\n",
    "    y_pred = int(top_i[0][0])\n",
    "    if y_pred != int(y.data[0]):\n",
    "        nb_errors += 1\n",
    "success_rate = (iter_example - nb_errors) / float(iter_example)\n",
    "print success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_to_rows(features, labels):\n",
    "    rows = np.hstack((features, labels))\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/tmp/train.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
